{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Pokemon classification on iOS using Convolutional Neural Network based on Keras\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***First you need to download dataset and Swift code to deploy image classification on iphone from Google Drive, since the files are too large to upload on github.***\n",
    "Please follow the instructions:\n",
    "1. Click the links to download [dataset]() and [pokemon_iOS]() from google drive.\n",
    "2. Click `dataset` / `pokemon_iOS` icon on the top with a down-arrow to download the whole folder. \n",
    "3. Click `Download` and wait for downloading.\n",
    "4. (If needed) Unzipping the file.\n",
    "4. Move the `dataset` and `pokemon_iOS` folder to the folder containing this `jupyter notebook`. In this study, the folder is `Project`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file '/Users/raymond/.matplotlib/matplotlibrc', line 2 ('backend: TkAgg')\n",
      "Duplicate key in file '/Users/raymond/.matplotlib/matplotlibrc', line 3 ('backend: TkAgg')\n",
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:TensorFlow version 2.4.1 detected. Last version known to be fully compatible is 2.2.0 .\n",
      "WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import load_model\n",
    "import coremltools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def build_SmallerVGGNet(width, height, depth, classes):\n",
    "    # initialize the model along with the input shape to be\n",
    "    # \"channels last\" and the channels dimension itself\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # if we are using \"channels first\", update the input shape\n",
    "    # and channels dimension\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "        input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] data matrix: 252.07MB\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 1.9067 - accuracy: 0.4969 - val_loss: 1.4968 - val_accuracy: 0.3404\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.6600 - accuracy: 0.8102 - val_loss: 1.6524 - val_accuracy: 0.3191\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.5028 - accuracy: 0.8369 - val_loss: 1.9118 - val_accuracy: 0.2340\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.4126 - accuracy: 0.8601 - val_loss: 1.8732 - val_accuracy: 0.2340\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.4218 - accuracy: 0.8702 - val_loss: 1.5960 - val_accuracy: 0.3830\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.3237 - accuracy: 0.9044 - val_loss: 1.9731 - val_accuracy: 0.3191\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3485 - accuracy: 0.8811 - val_loss: 2.5206 - val_accuracy: 0.2128\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2948 - accuracy: 0.8981 - val_loss: 3.4612 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3984 - accuracy: 0.8920 - val_loss: 5.1583 - val_accuracy: 0.2340\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.3858 - accuracy: 0.8761 - val_loss: 2.8200 - val_accuracy: 0.2979\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3218 - accuracy: 0.8895 - val_loss: 2.6157 - val_accuracy: 0.2979\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.2505 - accuracy: 0.9190 - val_loss: 3.6619 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2668 - accuracy: 0.9024 - val_loss: 3.4719 - val_accuracy: 0.3404\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2997 - accuracy: 0.9044 - val_loss: 4.5433 - val_accuracy: 0.2340\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2792 - accuracy: 0.9065 - val_loss: 1.8646 - val_accuracy: 0.5106\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2624 - accuracy: 0.9020 - val_loss: 5.0106 - val_accuracy: 0.2553\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2307 - accuracy: 0.9117 - val_loss: 3.3110 - val_accuracy: 0.2766\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1996 - accuracy: 0.9194 - val_loss: 2.9014 - val_accuracy: 0.4043\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1996 - accuracy: 0.9277 - val_loss: 3.2827 - val_accuracy: 0.3830\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1234 - accuracy: 0.9564 - val_loss: 2.6626 - val_accuracy: 0.4681\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2148 - accuracy: 0.9162 - val_loss: 2.9603 - val_accuracy: 0.3830\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2290 - accuracy: 0.9096 - val_loss: 1.9356 - val_accuracy: 0.4681\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2214 - accuracy: 0.9322 - val_loss: 2.3082 - val_accuracy: 0.4894\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.2022 - accuracy: 0.9310 - val_loss: 2.0080 - val_accuracy: 0.4894\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2146 - accuracy: 0.9399 - val_loss: 1.2206 - val_accuracy: 0.6383\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1343 - accuracy: 0.9531 - val_loss: 2.3002 - val_accuracy: 0.5532\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1524 - accuracy: 0.9556 - val_loss: 1.3261 - val_accuracy: 0.6596\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1585 - accuracy: 0.9458 - val_loss: 2.2238 - val_accuracy: 0.5745\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1204 - accuracy: 0.9559 - val_loss: 1.5612 - val_accuracy: 0.5957\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1247 - accuracy: 0.9550 - val_loss: 1.3954 - val_accuracy: 0.7021\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1444 - accuracy: 0.9466 - val_loss: 1.6169 - val_accuracy: 0.6170\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 1.5593 - val_accuracy: 0.6596\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.1635 - accuracy: 0.9484 - val_loss: 2.4532 - val_accuracy: 0.6383\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.1350 - accuracy: 0.9608 - val_loss: 0.8483 - val_accuracy: 0.7872\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.1019 - accuracy: 0.9621 - val_loss: 1.2379 - val_accuracy: 0.7660\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1014 - accuracy: 0.9648 - val_loss: 1.2734 - val_accuracy: 0.7447\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.1158 - accuracy: 0.9570 - val_loss: 1.2151 - val_accuracy: 0.8511\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1305 - accuracy: 0.9476 - val_loss: 0.9596 - val_accuracy: 0.8511\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1228 - accuracy: 0.9590 - val_loss: 1.3560 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0734 - accuracy: 0.9753 - val_loss: 0.4710 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.1328 - accuracy: 0.9501 - val_loss: 1.2117 - val_accuracy: 0.8511\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1467 - accuracy: 0.9466 - val_loss: 1.1571 - val_accuracy: 0.8511\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 1.2905 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0794 - accuracy: 0.9692 - val_loss: 0.7946 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0907 - accuracy: 0.9702 - val_loss: 1.2232 - val_accuracy: 0.8723\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0760 - accuracy: 0.9728 - val_loss: 1.0136 - val_accuracy: 0.8511\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.1081 - accuracy: 0.9663 - val_loss: 1.2407 - val_accuracy: 0.8723\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0761 - accuracy: 0.9736 - val_loss: 1.0960 - val_accuracy: 0.8723\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.1056 - accuracy: 0.9655 - val_loss: 2.1574 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.0738 - accuracy: 0.9736 - val_loss: 1.4207 - val_accuracy: 0.8298\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "[INFO] serializing network...\n",
      "[INFO] serializing label binarizer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    "\n",
    "plotting = 'plot.png'\n",
    "save_path = 'Pokemon.model'\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images(\"./dataset\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "    data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for validation and testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.2, random_state=42)\n",
    "(valX, testX, valY, testY) = train_test_split(testX,\n",
    "    testY, test_size=0.2, random_state=42)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = build_SmallerVGGNet(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "    depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "checkpoint = ModelCheckpoint(save_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "H = model.fit(\n",
    "    x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1,\n",
    "    callbacks = [checkpoint]\n",
    ")\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "#model.save(save_path, save_format=\"h5\")\n",
    "\n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open('label.pickle', \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 3, 3, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 42,599,557\n",
      "Trainable params: 19,009,541\n",
      "Non-trainable params: 23,590,016\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.8752 - acc: 0.3433 - val_loss: 3.7041 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.21277, saving model to Res50.hdf5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.3337 - acc: 0.4903 - val_loss: 4.8182 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.21277\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.2151 - acc: 0.5207 - val_loss: 5.0590 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.21277\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.1743 - acc: 0.5392 - val_loss: 4.1132 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.21277\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 1.1730 - acc: 0.5587 - val_loss: 3.7258 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.21277\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.0229 - acc: 0.6123 - val_loss: 5.5586 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.21277\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.0384 - acc: 0.5984 - val_loss: 5.0610 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.21277\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.9916 - acc: 0.6189 - val_loss: 4.1211 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.21277\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.9499 - acc: 0.6199 - val_loss: 4.4881 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.21277\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.9077 - acc: 0.6487 - val_loss: 4.3913 - val_acc: 0.2766\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.21277 to 0.27660, saving model to Res50.hdf5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.9635 - acc: 0.6100 - val_loss: 3.5836 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.27660\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8932 - acc: 0.6511 - val_loss: 4.0876 - val_acc: 0.2128\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.27660\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8497 - acc: 0.6741 - val_loss: 3.1909 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.27660\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.9218 - acc: 0.6457 - val_loss: 3.0171 - val_acc: 0.2979\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.27660 to 0.29787, saving model to Res50.hdf5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.8532 - acc: 0.6829 - val_loss: 2.1022 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.29787 to 0.36170, saving model to Res50.hdf5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.8946 - acc: 0.6579 - val_loss: 1.9756 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.36170\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8738 - acc: 0.6816 - val_loss: 2.3231 - val_acc: 0.3191\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.36170\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8584 - acc: 0.6918 - val_loss: 1.8203 - val_acc: 0.4894\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.36170 to 0.48936, saving model to Res50.hdf5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.8969 - acc: 0.6797 - val_loss: 2.4608 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.48936\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.8411 - acc: 0.6678 - val_loss: 3.8613 - val_acc: 0.2340\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.48936\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7905 - acc: 0.7029 - val_loss: 4.3991 - val_acc: 0.2766\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.48936\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8160 - acc: 0.6867 - val_loss: 2.8087 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.48936\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7862 - acc: 0.7100 - val_loss: 2.8237 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.48936\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7540 - acc: 0.6906 - val_loss: 1.8782 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.48936\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8049 - acc: 0.6985 - val_loss: 3.9365 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.48936\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7417 - acc: 0.7257 - val_loss: 2.3167 - val_acc: 0.3617\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.48936\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7980 - acc: 0.7265 - val_loss: 2.1499 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.48936\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8222 - acc: 0.6819 - val_loss: 2.5644 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.48936\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.7972 - acc: 0.6985 - val_loss: 1.3292 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.48936 to 0.55319, saving model to Res50.hdf5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.6796 - acc: 0.7238 - val_loss: 1.3558 - val_acc: 0.6170\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.55319 to 0.61702, saving model to Res50.hdf5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.7106 - acc: 0.7282 - val_loss: 1.9382 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61702\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.7668 - acc: 0.7254 - val_loss: 1.8655 - val_acc: 0.5319\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61702\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.7611 - acc: 0.7376 - val_loss: 2.0567 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.61702\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.7258 - acc: 0.7248 - val_loss: 2.4898 - val_acc: 0.5106\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.61702\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.7475 - acc: 0.7206 - val_loss: 2.1870 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61702\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.6763 - acc: 0.7436 - val_loss: 1.9430 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61702\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.7285 - acc: 0.7166 - val_loss: 2.8639 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.61702\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.6746 - acc: 0.7662 - val_loss: 1.6231 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61702\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.6665 - acc: 0.7615 - val_loss: 2.0031 - val_acc: 0.5106\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.61702\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.6853 - acc: 0.7541 - val_loss: 2.0304 - val_acc: 0.5319\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.61702\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.6981 - acc: 0.7300 - val_loss: 1.5012 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.61702\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.6347 - acc: 0.7432 - val_loss: 1.3797 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.61702 to 0.68085, saving model to Res50.hdf5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.7025 - acc: 0.7397 - val_loss: 1.0188 - val_acc: 0.6383\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.68085\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6945 - acc: 0.7420 - val_loss: 1.0279 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.68085\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.8170 - acc: 0.6708 - val_loss: 1.1696 - val_acc: 0.6170\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.68085\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7040 - acc: 0.7454 - val_loss: 1.7477 - val_acc: 0.5745\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.68085\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6711 - acc: 0.7493 - val_loss: 2.4225 - val_acc: 0.4894\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.68085\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.7173 - acc: 0.7440 - val_loss: 3.0862 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.68085\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.6906 - acc: 0.7355 - val_loss: 2.9175 - val_acc: 0.4043\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.68085\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.6517 - acc: 0.7699 - val_loss: 2.4207 - val_acc: 0.4681\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.68085\n"
     ]
    }
   ],
   "source": [
    "pretrain = ResNet50(weights = 'imagenet',\n",
    "              include_top = False,\n",
    "              input_shape = IMAGE_DIMS)\n",
    "\n",
    " \n",
    "# Model definition\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated \n",
    "# during training inorder to extract features\n",
    "pretrain.trainable=False\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "model.add(pretrain)\n",
    " \n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(Dropout(0.2))     \n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "checkpoint = ModelCheckpoint('Res50.hdf5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "historyres = model.fit(\n",
    "    x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1,\n",
    "    callbacks = [checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 96s 1us/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 1, 1, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 24,037,413\n",
      "Trainable params: 2,232,325\n",
      "Non-trainable params: 21,805,088\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 14s 652ms/step - loss: 1.6592 - acc: 0.4377 - val_loss: 2.3935 - val_acc: 0.5106\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51064, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 8s 564ms/step - loss: 0.9385 - acc: 0.6842 - val_loss: 1.0225 - val_acc: 0.6383\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51064 to 0.63830, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.8322 - acc: 0.6874 - val_loss: 0.7823 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.63830 to 0.68085, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 8s 573ms/step - loss: 0.7071 - acc: 0.7364 - val_loss: 0.7532 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.68085\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 9s 643ms/step - loss: 0.6254 - acc: 0.7710 - val_loss: 0.8508 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.68085\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 10s 707ms/step - loss: 0.6091 - acc: 0.7684 - val_loss: 0.7141 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.68085 to 0.72340, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 8s 556ms/step - loss: 0.6043 - acc: 0.7779 - val_loss: 0.8055 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72340\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 8s 556ms/step - loss: 0.6210 - acc: 0.7798 - val_loss: 0.6765 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.72340 to 0.78723, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 8s 552ms/step - loss: 0.5926 - acc: 0.7820 - val_loss: 0.6779 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78723\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 8s 550ms/step - loss: 0.5685 - acc: 0.8066 - val_loss: 0.8033 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78723\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 8s 560ms/step - loss: 0.5681 - acc: 0.8057 - val_loss: 0.7224 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78723\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 8s 571ms/step - loss: 0.5022 - acc: 0.8233 - val_loss: 0.5539 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78723\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 8s 578ms/step - loss: 0.5372 - acc: 0.7843 - val_loss: 0.5492 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78723\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 8s 564ms/step - loss: 0.5277 - acc: 0.8024 - val_loss: 0.5484 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78723\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 8s 575ms/step - loss: 0.4918 - acc: 0.8219 - val_loss: 0.5998 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78723\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 8s 566ms/step - loss: 0.5159 - acc: 0.8219 - val_loss: 0.5060 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78723\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 8s 564ms/step - loss: 0.4426 - acc: 0.8392 - val_loss: 0.6905 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78723\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 8s 557ms/step - loss: 0.5010 - acc: 0.8273 - val_loss: 0.7347 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78723\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 8s 570ms/step - loss: 0.4097 - acc: 0.8686 - val_loss: 0.7311 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78723\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 8s 577ms/step - loss: 0.4732 - acc: 0.8181 - val_loss: 0.7508 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.78723\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 9s 643ms/step - loss: 0.4741 - acc: 0.8394 - val_loss: 0.6544 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.78723\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 8s 569ms/step - loss: 0.4412 - acc: 0.8352 - val_loss: 0.7018 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.78723\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 8s 563ms/step - loss: 0.4032 - acc: 0.8491 - val_loss: 0.6450 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.78723\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 8s 574ms/step - loss: 0.4631 - acc: 0.8339 - val_loss: 0.5616 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.78723\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 8s 554ms/step - loss: 0.4114 - acc: 0.8501 - val_loss: 0.6711 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78723\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 8s 554ms/step - loss: 0.3632 - acc: 0.8645 - val_loss: 0.6296 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.78723\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 8s 553ms/step - loss: 0.3802 - acc: 0.8601 - val_loss: 0.5814 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.78723\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 8s 557ms/step - loss: 0.4226 - acc: 0.8521 - val_loss: 0.5703 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.78723\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 0.4184 - acc: 0.8472 - val_loss: 0.6742 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.78723\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 8s 563ms/step - loss: 0.4501 - acc: 0.8282 - val_loss: 0.6514 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.78723\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 0.4120 - acc: 0.8451 - val_loss: 0.6504 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.78723\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 8s 554ms/step - loss: 0.4308 - acc: 0.8370 - val_loss: 0.7139 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.78723\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 10s 711ms/step - loss: 0.3438 - acc: 0.8608 - val_loss: 0.6448 - val_acc: 0.7872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_acc did not improve from 0.78723\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 13s 880ms/step - loss: 0.3906 - acc: 0.8439 - val_loss: 0.6076 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.78723\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 12s 815ms/step - loss: 0.3960 - acc: 0.8549 - val_loss: 0.5726 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.78723\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 9s 597ms/step - loss: 0.4003 - acc: 0.8569 - val_loss: 0.6369 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.78723\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 10s 666ms/step - loss: 0.4097 - acc: 0.8440 - val_loss: 0.6503 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.78723\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 11s 752ms/step - loss: 0.3860 - acc: 0.8470 - val_loss: 0.5960 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.78723 to 0.80851, saving model to Incep.model\n",
      "INFO:tensorflow:Assets written to: Incep.model/assets\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 8s 554ms/step - loss: 0.4229 - acc: 0.8395 - val_loss: 0.6350 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.80851\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 8s 552ms/step - loss: 0.4198 - acc: 0.8502 - val_loss: 0.6114 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80851\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 8s 557ms/step - loss: 0.3677 - acc: 0.8832 - val_loss: 0.6411 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.80851\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 8s 556ms/step - loss: 0.4117 - acc: 0.8524 - val_loss: 0.6663 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.80851\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 8s 551ms/step - loss: 0.3219 - acc: 0.8912 - val_loss: 0.6880 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.80851\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 0.3549 - acc: 0.8846 - val_loss: 0.6026 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80851\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 8s 562ms/step - loss: 0.3864 - acc: 0.8630 - val_loss: 0.8036 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.80851\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 8s 564ms/step - loss: 0.3632 - acc: 0.8530 - val_loss: 0.6871 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.80851\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 8s 552ms/step - loss: 0.3214 - acc: 0.8852 - val_loss: 0.5801 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.80851\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 8s 565ms/step - loss: 0.3764 - acc: 0.8694 - val_loss: 0.6477 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.80851\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 8s 548ms/step - loss: 0.2916 - acc: 0.8925 - val_loss: 0.6679 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.80851\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 8s 550ms/step - loss: 0.3426 - acc: 0.8755 - val_loss: 0.6386 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.80851\n"
     ]
    }
   ],
   "source": [
    "pretrain = InceptionV3(weights = 'imagenet',\n",
    "              include_top = False,\n",
    "              input_shape = IMAGE_DIMS)\n",
    "\n",
    " \n",
    "# Model definition\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Freeze the convolutional base of VGG16 to prevent the pre-trained weights being updated \n",
    "# during training inorder to extract features\n",
    "pretrain.trainable=False\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "model.add(pretrain)\n",
    " \n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())                 # normalize and scale inputs or activations\n",
    "model.add(Dropout(0.2))                         # applies dopout to the input which will randomly disable 20% of hidden units\n",
    "\n",
    "# add densely-connected NN layer with 128 hidden units\n",
    "model.add(Dense(units=128, activation='relu')) # use ReLU activation function\n",
    "model.add(BatchNormalization())                # normalize and scale inputs or activations\n",
    "model.add(Dropout(0.2))     \n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "checkpoint = ModelCheckpoint('Incep.model', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "historyin = model.fit(\n",
    "    x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1,\n",
    "    callbacks = [checkpoint]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading class labels from label binarizer\n",
      "[INFO] class labels: ['bulbasaur', 'charmander', 'mewtwo', 'pikachu', 'squirtle']\n",
      "[INFO] loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raymond/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] converting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:01<00:00,  3.31 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 71/71 [00:00<00:00, 337.94 ops/s]\n",
      "Running MIL optimization passes: 100%|██████████| 16/16 [00:00<00:00, 117.19 passes/s]\n",
      "Translating MIL ==> MLModel Ops: 100%|██████████| 101/101 [00:01<00:00, 77.93 ops/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model as pokemon.mlmodel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# converting to CoreML\n",
    "\n",
    "# load the class labels\n",
    "print(\"[INFO] loading class labels from label binarizer\")\n",
    "lb = pickle.loads(open('label.pickle', \"rb\").read())\n",
    "class_labels = lb.classes_.tolist()\n",
    "print(\"[INFO] class labels: {}\".format(class_labels))\n",
    "\n",
    "# load the trained convolutional neural network\n",
    "print(\"[INFO] loading model...\")\n",
    "model = load_model('Pokemon.model')\n",
    "\n",
    "# convert the model to coreml format\n",
    "print(\"[INFO] converting model\")\n",
    "coreml_model = coremltools.converters.convert(model,\n",
    "    input_names=\"image\",\n",
    "    image_input_names=\"image\",\n",
    "    image_scale=1/255.0,\n",
    "    class_labels=class_labels,\n",
    "    is_bgr=True)\n",
    "\n",
    "# save the model to disk\n",
    "output = \"pokemon.mlmodel\"\n",
    "print(\"[INFO] saving model as {}\".format(output))\n",
    "coreml_model.save(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
